/**
 * AI-Generated Content Type Definitions
 * Requirements: 2.1, 5.1, 11.1
 * 
 * This module defines types for the enhanced AI content generation system,
 * including narratives, images, videos, caching, and cost tracking.
 */

import type { GeoCoordinate, GeologicalLayer, Narrative } from 'deep-time-core/types';

// ============================================
// Media Resolution Types
// ============================================

/**
 * Media resolution options for image generation
 * Requirement 7.4: Use MEDIA_RESOLUTION_MEDIUM for optimal quality-cost balance
 */
export type MediaResolution = 'LOW' | 'MEDIUM' | 'HIGH';

// ============================================
// Location Context Types
// ============================================

/**
 * Extended location context for AI content generation
 * Requirement 1.2: Include location-specific geological metadata in prompts
 */
export interface LocationContext {
  /** Geographic coordinates */
  coordinates: GeoCoordinate;
  /** Human-readable place name (from geocoding) */
  placeName: string;
  /** Notable geological features at this location */
  geologicalFeatures: string[];
  /** Nearby landmarks for context */
  nearbyLandmarks: string[];
}

// ============================================
// Token Usage and Cost Tracking Types
// ============================================

/**
 * Token usage metrics for a single API call
 * Requirement 11.1: Log token counts for input, output, and cached tokens
 */
export interface TokenUsage {
  /** Number of input tokens sent to the model */
  inputTokens: number;
  /** Number of output tokens generated by the model */
  outputTokens: number;
  /** Number of tokens served from implicit/explicit cache */
  cachedTokens: number;
  /** Calculated cost in USD for this API call */
  totalCost: number;
}

/**
 * Daily cost tracking record
 * Requirement 11.5: Track usage against defined thresholds
 */
export interface DailyCostRecord {
  /** Date string in YYYY-MM-DD format */
  date: string;
  /** Total cost for text generation */
  textCost: number;
  /** Total cost for image generation */
  imageCost: number;
  /** Total cost for video generation */
  videoCost: number;
  /** Combined total cost for the day */
  totalCost: number;
  /** Number of API calls made */
  apiCalls: number;
  /** Number of cache hits (avoided API calls) */
  cacheHits: number;
}

// ============================================
// Enhanced Narrative Types
// ============================================

/**
 * Enhanced narrative with location context and generation metadata
 * Extends the base Narrative type with AI-specific fields
 * Requirement 2.1: Use Gemini 2.5 Flash for narrative generation
 */
export interface EnhancedNarrative extends Narrative {
  /** Location context used for generation */
  locationContext: LocationContext;
  /** Timestamp when this narrative was generated */
  generatedAt: Date;
  /** Model identifier used for generation */
  modelUsed: string;
  /** Token usage and cost for this generation */
  tokenUsage: TokenUsage;
}

// ============================================
// Generated Image Types
// ============================================

/**
 * Generated image with metadata
 * Requirement 3.2: Use Gemini 2.5 Flash Image model
 */
export interface GeneratedImage {
  /** Unique identifier for this image */
  id: string;
  /** Image binary data as Blob */
  imageData: Blob;
  /** MIME type (e.g., 'image/png', 'image/jpeg') */
  mimeType: string;
  /** Image width in pixels */
  width: number;
  /** Image height in pixels */
  height: number;
  /** Prompt used to generate this image */
  prompt: string;
  /** Timestamp when this image was generated */
  generatedAt: Date;
  /** Model identifier used for generation */
  modelUsed: string;
  /** Resolution setting used */
  resolution: MediaResolution;
  /** Cost in USD for this generation */
  cost: number;
}

/**
 * Options for image generation
 * Requirement 7.4: Use MEDIA_RESOLUTION_MEDIUM for optimal quality-cost balance
 */
export interface ImageGenerationOptions {
  /** Resolution setting (defaults to MEDIUM) */
  resolution?: MediaResolution;
  /** Aspect ratio for the generated image */
  aspectRatio?: '16:9' | '4:3' | '1:1';
  /** Visual style for the image */
  style?: 'photorealistic' | 'artistic' | 'scientific';
}

// ============================================
// Generated Video Types
// ============================================

/**
 * Video generation operation handle for async polling
 * Requirement 4.5: Use Veo 3.1 Fast model with async operation handling
 */
export interface VideoOperation {
  /** Unique operation identifier from the API */
  operationId: string;
  /** Current status of the video generation */
  status: 'pending' | 'processing' | 'complete' | 'failed';
  /** Estimated completion timestamp */
  estimatedCompletion: Date;
  /** Progress percentage (0-100) */
  progress: number;
}

/**
 * Generated video with metadata
 * Requirement 4.1: Generate 4-6 second videos using Veo 3.1 Fast
 */
export interface GeneratedVideo {
  /** Unique identifier for this video */
  id: string;
  /** Video binary data as Blob */
  videoData: Blob;
  /** MIME type (e.g., 'video/mp4') */
  mimeType: string;
  /** Video duration in seconds */
  duration: number;
  /** Video width in pixels */
  width: number;
  /** Video height in pixels */
  height: number;
  /** Prompt used to generate this video */
  prompt: string;
  /** Timestamp when this video was generated */
  generatedAt: Date;
  /** Model identifier used for generation */
  modelUsed: string;
  /** Cost in USD for this generation */
  cost: number;
  /** Number of times this video has been extended (max 5) */
  extensionCount?: number;
  /** ID of the source video if this is an extension */
  extendedFromVideoId?: string;
}

/**
 * Options for video generation
 * Requirement 4.1: Generate 4-6 second videos
 */
export interface VideoGenerationOptions {
  /** Video duration in seconds (4, 6, or 8) */
  duration?: 4 | 6 | 8;
  /** Video resolution */
  resolution?: '720p' | '1080p';
  /** Whether to use a generated image as the first frame */
  useImageAsFirstFrame?: boolean;
}

/**
 * Options for video extension
 * Extends existing video by 7 seconds using Veo 3.1
 */
export interface VideoExtensionOptions {
  /** The source video to extend */
  sourceVideo: GeneratedVideo;
  /** Prompt describing what should happen in the extension */
  extensionPrompt: string;
  /** Era name for context */
  eraName: string;
  /** Location name for context */
  placeName: string;
}

/** Maximum number of extensions allowed per video chain */
export const MAX_VIDEO_EXTENSIONS = 5;

// ============================================
// Generation Metadata Types
// ============================================

/**
 * Metadata about a content generation operation
 * Tracks timing, costs, and models used
 */
export interface GenerationMetadata {
  /** Timestamp when generation started */
  generatedAt: Date;
  /** Location for which content was generated */
  location: GeoCoordinate;
  /** Geological era for which content was generated */
  era: GeologicalLayer;
  /** Total cost in USD for all generations */
  totalCost: number;
  /** Total tokens used across all generations */
  totalTokens: number;
  /** Total time taken for generation in milliseconds */
  generationDuration: number;
  /** List of model identifiers used */
  modelsUsed: string[];
}

// ============================================
// Combined Content Types
// ============================================

/**
 * Complete AI-generated content for a location-era combination
 * Requirement 2.1, 3.1, 4.1: Generate text, image, and video content
 */
export interface AIGeneratedContent {
  /** Enhanced narrative with location context */
  text: EnhancedNarrative;
  /** Generated era visualization image (null if generation failed) */
  image: GeneratedImage | null;
  /** Generated video clip (null if generation failed or in progress) */
  video: GeneratedVideo | null;
  /** Metadata about the generation process */
  generationMetadata: GenerationMetadata;
}

/**
 * Complete era content including cache metadata
 * Used by ContentOrchestrator for cache-first retrieval
 */
export interface EraContent {
  /** Enhanced narrative */
  narrative: EnhancedNarrative;
  /** Generated image (null if unavailable) */
  image: GeneratedImage | null;
  /** Generated video (null if unavailable) */
  video: GeneratedVideo | null;
  /** Cache metadata for this content */
  cacheMetadata: CacheMetadata;
}

// ============================================
// Cache Types
// ============================================

/**
 * Cache metadata for stored content
 * Requirement 5.1: Store with cache key combining location and era
 * Requirement 5.2: Verify cache entry has not exceeded TTL
 */
export interface CacheMetadata {
  /** Cache key in format: ${latitude}_${longitude}_${eraId} */
  cacheKey: string;
  /** Timestamp when content was cached */
  cachedAt: Date;
  /** Timestamp when cache entry expires (30-day TTL) */
  expiresAt: Date;
  /** Timestamp when content was last accessed (for LRU) */
  lastAccessed: Date;
  /** Size of cached content in bytes */
  size: number;
  /** Schema version for migration support */
  version: number;
}

/**
 * Complete cache entry for storage
 * Requirement 5.1: Cache key combining location coordinates and era identifier
 */
export interface CacheEntry {
  /** Cache key: ${lat}_${lon}_${eraId} */
  key: string;
  /** The AI-generated content */
  content: AIGeneratedContent;
  /** Cache metadata */
  metadata: CacheMetadata;
}

/**
 * Cached era content with metadata
 * Returned by CacheManager.getContent()
 */
export interface CachedEraContent {
  /** The era content */
  content: EraContent;
  /** Cache metadata */
  metadata: CacheMetadata;
}

/**
 * Cache statistics for monitoring
 * Requirement 11.2: Log cache hit events
 */
export interface CacheStats {
  /** Total number of cached entries */
  totalEntries: number;
  /** Total size of cache in bytes */
  totalSize: number;
  /** Cache hit rate (0-1) */
  hitRate: number;
  /** Timestamp of oldest cache entry */
  oldestEntry: Date;
  /** Timestamp of newest cache entry */
  newestEntry: Date;
}

// ============================================
// Error Types
// ============================================

/**
 * AI-related error types for error handling
 * Requirement 9.1-9.5: Graceful degradation and fallbacks
 */
export type AIErrorType =
  | 'api_error'           // Gemini/Veo API failure
  | 'rate_limit'          // API rate limit exceeded (429)
  | 'invalid_key'         // API key missing or invalid
  | 'parse_error'         // Response parsing failure
  | 'cache_error'         // IndexedDB operation failure
  | 'network_error'       // Network connectivity issue
  | 'generation_timeout'; // Generation took too long

/**
 * Error recovery strategy configuration
 * Requirement 9.5: Retry with exponential backoff
 */
export interface ErrorRecoveryStrategy {
  /** Type of error this strategy handles */
  errorType: AIErrorType;
  /** Fallback behavior to use */
  fallbackBehavior: 'use_cache' | 'use_fallback' | 'retry' | 'fail_gracefully';
  /** Retry configuration (if fallbackBehavior is 'retry') */
  retryConfig?: {
    /** Maximum number of retry attempts */
    maxAttempts: number;
    /** Backoff delays in milliseconds for each attempt */
    backoffMs: number[];
  };
}

// ============================================
// IndexedDB Schema Types
// ============================================

/**
 * IndexedDB schema for AI content caching
 * Requirement 5.1: Store in IndexedDB with cache key
 * Requirement 11.1: Cost tracking object store
 */
export interface DeepTimeCacheDB {
  /** Era content object store */
  eraContent: {
    key: string;
    value: CacheEntry;
    indexes: {
      location: string;
      era: string;
      cachedAt: Date;
      expiresAt: Date;
    };
  };

  /** Media blobs object store for images/videos */
  mediaBlobs: {
    key: string; // image or video ID
    value: {
      id: string;
      type: 'image' | 'video';
      data: Blob;
      metadata: Record<string, unknown>;
    };
  };

  /** Cost tracking object store */
  costTracking: {
    key: string; // date string YYYY-MM-DD
    value: DailyCostRecord;
  };
}

// ============================================
// Constants
// ============================================

/** Default TTL for cached content (30 days in milliseconds) */
export const CACHE_TTL_MS = 30 * 24 * 60 * 60 * 1000;

/** Maximum cache size in bytes (50MB) */
export const MAX_CACHE_SIZE_BYTES = 50 * 1024 * 1024;

/** 
 * Default video duration in seconds (Veo 3.1 Fast supports 4, 6, or 8 seconds)
 * Requirement 5.1: Default to 4 seconds for cost optimization
 * Cost: 4 seconds × $0.15/second = $0.60 per video (33% savings vs 6 seconds)
 */
export const DEFAULT_VIDEO_DURATION = 4;

/** Minimum video duration in seconds */
export const MIN_VIDEO_DURATION = 4;

/** Maximum video duration in seconds (Veo 3.1 Fast supports up to 8 seconds) */
export const MAX_VIDEO_DURATION = 8;

/** Default image resolution */
export const DEFAULT_IMAGE_RESOLUTION: MediaResolution = 'MEDIUM';

/** Cost per 1M input tokens (Gemini 2.5 Flash) */
export const INPUT_COST_PER_1M = 0.30;

/** Cost per 1M output tokens (Gemini 2.5 Flash) */
export const OUTPUT_COST_PER_1M = 2.50;

/** 
 * Cost per 1M cached tokens (90% discount)
 * Requirement 2.1: Apply the correct 90% discount rate of $0.03 per 1M tokens
 * This is 10× cheaper than the full input price of $0.30 per 1M tokens
 */
export const CACHED_COST_PER_1M = 0.03;

/** Cost per image by resolution */
export const IMAGE_COST_BY_RESOLUTION: Record<MediaResolution, number> = {
  LOW: 0.02,
  MEDIUM: 0.039,
  HIGH: 0.08,
};

/** Cost per second for Veo 3.1 Fast video generation */
export const VIDEO_COST_PER_SECOND_FAST = 0.15;

/** Cost per second for Veo 3.1 Standard video generation */
export const VIDEO_COST_PER_SECOND_STANDARD = 0.40;

/** 
 * Default maximum output tokens for text generation
 * Requirement 4.1: Set maxOutputTokens to 2048 or less
 * 2048 tokens is sufficient for narrative JSON responses and prevents token waste
 */
export const DEFAULT_MAX_OUTPUT_TOKENS = 2048;
